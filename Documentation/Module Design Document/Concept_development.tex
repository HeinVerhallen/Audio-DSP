\section{Concept overview}

\section{Architecture}
The lower level design of the system are explained in the architecture design of the system. 

\subsection{Front-end}
The architecture design of the front-end of the Audio-DSP is shown in figure \ref{fig:arch-front-end}. The heart of the front-end consists of two stereo ADCs, although they are not necessarily used in stereo, and it is up to the user to choose how to utilize them. In essence, the audio DSP's front-end can be seen as four separate mono ADCs, as they provide the user with complete flexibility in their application. If time permits, the audio DSP will also feature a USB input, allowing direct digital audio input from a computer. This eliminates the need for digital-to-analog conversion by the computer's DAC and analog-to-digital conversion by the audio DSP. In theory, this USB input should offer the highest audio quality.

CH1 and CH2 each have a DPDT relay that enables the user to select between RCA or jack inputs. CH1 and CH2 are not required to use the same connector type, providing maximum flexibility to the user.

Following the input section, there are RC low-pass filters that effectively suppress high-frequency RF noise, as subsequent stages are less efficient in this regard. ESD protection diodes are then employed to divert excessive incoming voltage during an electrostatic discharge event to the system's power rails. The current during an ESD event is limited by the resistor or the RC filter.

After the RC filter and ESD protection, the signal is buffered to ensure that the preceding and subsequent stages do not interfere with each other.

The unbalanced channels, CH1 and CH2, are equipped with a volume control IC that can amplify or attenuate the incoming signal based on user preferences. This ensures optimal utilization of the ADCs' voltage range, enhancing audio quality. This volume control is particularly useful when using a guitar, as the output voltage of a guitar depends heavily on the type of guitar and playing style.

CH1 to CH4 are equipped with VU meters to visualize the amplitude of the incoming signal and detect any clipping. This information can be used to adjust the gain of the volume controller on CH1 and CH2. Each VU meter has buffers, not necessarily due to low input impedance, but primarily to minimize the surface area of current loops for sensitive signals. These buffers isolate the sensitive signal from the VU measurement.

Just before the actual ADCs, there is a differential active low-pass filter that serves as an anti-aliasing filter for the ADCs. This same LPF provides the audio signal with a DC offset voltage equal to half of the reference voltage of the used ADCs. This way, the audio signal is superimposed around a DC offset, allowing an ADC with an asymmetric supply voltage to accurately perceive the AC voltage of the audio signal. This DC offset reference voltage is generated by the ADCs and further filtered by an RC filter and buffered by an op-amp. A differential filter is employed to utilize Kelvin connections, ensuring that the differential voltage of the audio signal is independent of the voltage across the ground plane. This is the same reason why balanced XLR connectors are commonly used in professional audio, and why CH3 and CH4 are fully differential. When explaining the PCB layout, CH1 and CH2 will also be differentially routed, utilizing various Kelvin connections. However, this will never be as effective as the fully balanced XLR channels, CH3 and CH4.

The optional USB connection, CH5, is also protected by ESD diodes and then directly connected to the FPGA, which will convert the USB signal into the desired data format.

Finally, the digitized data is sent to the FPGA through the $I^2S$ protocol, where it can be processed. Due to the relatively high data rate of the I2S data, these connections are equipped with EMI reduction resistors, which essentially form an RC filter with the capacitance of the PCB trace and the ground plane, while also acting as series terminations.

\begin{figure}[ht]
    \includegraphics[width=\linewidth]{Front-end.png}\\    
    \caption{Front-end architecture of audio-DSP}
    \label{fig:arch-front-end}
\end{figure}

\subsection{Audio-DSP}
\begin{figure}[ht]
    \includegraphics[width=\linewidth]{Audio-DSP architecture.png}\\    
    \caption{Top-level architecture of audio-DSP}
    \label{fig:arch-top}
\end{figure}

In figure \ref{fig:arch-top} you see the architecture design of the Audio-DSP. Compared to the system context diagram of the Audio-DSP the block is now much more detailed. For instance the input samplers are replaced by $I^2S$ decoders and the output signals are now encoded to $I^2S$. Because most ADCs and DACs use the $I^2S$ protocol to transfer audio data it has been chosen to use the $I^2S$ protocol. The $I^2S$ encoders and decoders each have a left and right input and output. This is because the $I^2S$ protocol transfers a stereo audio signal. But this system uses mono signals. Therefore the system inputs the mono signals on the left and right inputs. This gives the system the ability to transfer two audio channels via one $I^2S$ bus.

The MUX in each of the signal processor managers is controlled via a 3-bit select line. This select line comes from the controller. For the controller to be able to handle all the multiplexers in each signal processor manager, 3-bits $\cdot$ 6 channels = 18 bits are needed. To select the RCA or 6.35mm jack input a 2-bit select line is used.

In order for the signal processor to modify the signal with various digital effects, memory is needed. This memory is stored inside the signal processor block itself. To access and modify the memory some kind of communication protocol had to be chosen in order for the controller to configure the effect parameters. For this a register based memory has been chosen.

Looking at the system requirements it is known that the user is able to adjust the position of each effect in the effects loop. Therefore the signal processor needs registers to store the position of each effect. The system must support at least five effects and should support at least twenty effects. Thus in order to fulfill all the requirements the signal processor should be able to position twenty effects. For this we would need at least 5 bits at each position. The various effects available to the user have configurable parameters. Therefore each effect also needs a register in the signal processor block. Also the equalizer settings are adjustable by the user. This means the equalizer also has a register with data.

The size of the registers can be very large. But to make the communication to the signal processor intuitive the registers will be limited to a maximum amount of bits. In order to choose the most efficient register size the registers should use most of its bits. The size of the register is of no importance for the effect and equalizer parameters as the size only affects the resolution of the parameters. But for the position register 5-bits per position are needed. Thus the register should be dividable by 5 in order to use the most of the registers bits. As there are 20 positions it is chosen to have four position registers with 5 positions (see figure \ref{fig:reg-position}).
This means the register size will be 25 bits.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.4\textwidth]{Position register design}
    \caption{Effect loop position 0 to 4 register}
    \label{fig:reg-position}
\end{figure}

Now that the register size has been defined we need to define the amount of registers needed. The system has 20 effects, therefore 20 effect parameter registers. Each effect needs to be positioned in the position registers which there are four of. Then the equalizer and volume registers are left. when using 5 bits for selecting the registers we would be able to access up to 32 registers. This means that there are $32 - (20 + 4) = 8$ registers left for the equalizer and volume parameters. That is more than enough for these registers.

Thus the data bus will be 25 bits and the register selector line will be 5 bits. With these two lines every register can be accessed by the controller. Now the memory needs to know if the data needs to be read or written. This is indicated by the R/W signal. When this signal is low the memory will be written and when the signal is high the memory will be read.

It is undesired that every signal processor memory will be read or written constantly. Therefore each signal processor block has an enable. When this enable signal is high the memory can be read or written. This gives the controller the ability to read or write to only one signal processor memory at a time. And the ability to write multiple signal processor memories at once.

\subsubsection{Signal processor}
\begin{figure}[ht]
    \includegraphics[width=\linewidth]{Signal processor architecture}
    \caption{Signal processor architecture}
    \label{fig:arch-signal-processor}
\end{figure}

The signal processor has to load a new sample into the effect loop and the previous modified sample to the output on the sample frequency. The sample frequency of the Audio-DSP is 192kHz. This means that the signal processor has $\frac{1}{192 \cdot 10^3} \approx 5 \mu s$ to process the sample. With a clock of 50MHz the sample must be modified and loaded into the output within $\frac{50 \cdot 10^6}{192 \cdot 10^3}=260$ clock ticks.

When a sample has been loaded into the signal processor, it is fed into the effect processor manager (see \ref{fig:arch-signal-processor}). The effect processor manager houses multiple effects processor in series. The sample will go through these effect processors. Each effect processor can be configured to be a certain effect (see \ref{fig:arch-effect-processor}). Because the system has at least twenty effects, the amount of bits the selector needs is 5 bits.

Each effect modifies the signal by applying a transfer function to the sample. The variables in that transfer function are configured by the user via the user interface. Therefore the effect processors needs to get the variables from the controller block, which gets the variables from the register bank. After the sample has gone through all the effect processors the modified sample waits before it is shifted out of the signal processor. 

\begin{figure}[ht]
    \includegraphics[width=\linewidth]{Effect processor architecture}
    \caption{Effect processor architecture}
    \label{fig:arch-effect-processor}
\end{figure}

\subsection{Back-end}
The architecture design of the back-end of the Audio-DSP is shown in figure \ref{fig:arch-back-end}. The processed data is sent from the FPGA to the DACs via the I2S protocol. The back-end consists of three stereo DACs, which, like the front-end, can be used as six separate mono channels depending on the user's preferences. Similar to the front-end, the I2S connections in the back-end are equipped with EMI reduction resistors due to the relatively high data rate.

Immediately after the DACs, differential low-pass filters are placed, serving as reconstruction filters. Finally, the signal is buffered to ensure that the output signals have relatively low impedance, reducing circuit noise.

CH1 and CH2 offer the most extensive features, providing the user with maximum flexibility. In addition to the standard balanced XLR output, each output channel in these channels is also equipped with an unbalanced RCA and jack connector. The RCA and jack connectors of the same channel are interconnected and carry the exact same signal. The output signal is always present on all outputs of that channel, as it does not adversely affect the system's performance. This way, the user does not need to consider whether a particular output connector has a signal or not. The connectors will be equipped with a small series resistor to minimize phase shift caused by the capacitance of the cables used, significantly improving system stability.

\begin{figure}[ht]
    \includegraphics[width=\linewidth]{Back-end.png}\\    
    \caption{Back-end architecture of audio-DSP}
    \label{fig:arch-back-end}
\end{figure}

\subsection{Power supplies}
The architecture design of the power supplies of the Audio-DSP is shown in figure \ref{fig:arch-power-supply}. The power supply section is composed of various power supplies. The ADCs and DACs impose high demands on the power supply since their analog voltages are directly referenced to the supply voltage. If the supply voltage of the analog components were to fluctuate due to potential power ripple, the digitized values from the ADCs could deviate by one or more bits. The same applies to the DACs, as the reconstructed analog voltage is directly dependent on the power supply voltage of the analog part of the DACs. To ensure that the noise caused by power fluctuations of the ADCs and DACs is smaller than the quantization error, very high requirements are set for these power supplies.

Since the availability of linear voltage regulator ICs is limited, and at the time of writing, no IC met these stringent requirements, it was decided to design and create discrete low-noise voltage regulators. Discrete designs offer the potential for much better performance than available ICs.

Similar to the ADCs and DACs, the op-amps also have high demands on power supply ripple, and therefore, comparable discrete low-noise linear regulators are used for them.

The digital side of the ADCs and DACs has much lower demands on power supply ripple, but datasheets recommend the use of linear voltage regulators for optimal performance. Hence, standard low dropout (LDO) linear voltage regulators will be used for this purpose. Discrete designs are overly emphasized for these applications.

To limit power losses and heat dissipation in the audio DSP, switching converters are used wherever possible due to their high efficiency. Buck converters are placed before the linear voltage regulators to pre-regulate the voltage, reducing the voltage drop across the linear voltage regulators and thus reducing the power dissipation.

The FPGA and signal relay are powered by a 12V buck converter. The standard power requirement for the FPGA is 12V at 2A, and to provide additional margin, our 12V power supply will be designed for a minimum of 3A to ensure sufficient current delivery and voltage stability.

The required negative power supply voltage is generated by a single-ended primary-inductor converter (SEPIC). This choice was made due to the ability to generate a negative power supply voltage, low voltage ripple, and high efficiency. The SEPIC receives 12V as an input voltage from a buck converter because the input voltage range of SEPIC converters is generally limited. The same buck converter used to power the FPGA and signal relay can be utilized for this purpose.

Ultimately, all power supplies are fed from an externally sourced 24V power supply for safety reasons. A 24V power supply was chosen because it was the most cost-effective at the time of writing. The voltage does not need to be exactly 24V since it will be further regulated by various switching regulators.

\begin{figure}[ht]
    \includegraphics[width=\linewidth]{Power supply.png}\\    
    \caption{Power supply architecture of audio-DSP}
    \label{fig:arch-power-supply}
\end{figure}


\section{Block diagrams}

\section{Modules}

\section{Design decisions}


